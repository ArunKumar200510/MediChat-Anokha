{"metadata":{"colab":{"name":"brain_tumor_classifier_resnet_torch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7974997,"sourceType":"datasetVersion","datasetId":4693204}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain Tumor Classification\n\nA Brain Tumor Classifier using fine-tuned ResNet50 Neural Network architecture with almost 99 % Accuracy achieved by applying the method of Transfer Learning.\n\nGiven an MRI image of brain, classify the tumor into **Meningioma, Glioma, and Pitutary**, if present. \n","metadata":{"id":"43754Epan7bx"}},{"cell_type":"markdown","source":"## Import Necessary Libraries\n\n\n\n* Numpy - For linear algebra operations \n* Torch - Pytorch Deep Learning Framework\n* Torch NN - Neural network class from Pytorch library\n* Torch NN Functional - Functional Neural Network class from Pytorch library\n* Torch Utils Data: DataLoader, Dataset - Dataset class used to create custom dataset class by subclassing it and DataLoader is used to laod data in batches using dataset class in real-time.\n* Torchvision: Transforms, Models - Trochvision provides augmentation techniques using transforms class and transfer learning models are available in models class\n* OS - To use Operating System methods\n* Random - To set random seed at specific places where random operations take place just so it happens the same way everytime it is executed\n* Pandas - To create DataFrame, CSV files, etc\n* Time - To perform date time operations\n* Seaborn - For sophisticated visualization\n* Pickle - To save and load binary files of our training data\n* Scikit-Learn - For evaluating our Classifier and for cross-validation split\n* Matplotlib - To visualize images, losses and accuracy\n* Google Colab Drive - To mount Google Drive so we can perform storage and loading operations using it\n\n","metadata":{"id":"s4k9AZlhoVgg"}},{"cell_type":"code","source":"!pip install torch torchvision scikit-learn pandas matplotlib seaborn","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:26:59.430721Z","iopub.execute_input":"2024-04-02T12:26:59.431071Z","iopub.status.idle":"2024-04-02T12:27:13.855446Z","shell.execute_reply.started":"2024-04-02T12:26:59.431042Z","shell.execute_reply":"2024-04-02T12:27:13.854194Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install intel-extension-for-pytorch scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:27:45.017585Z","iopub.execute_input":"2024-04-02T12:27:45.018437Z","iopub.status.idle":"2024-04-02T12:28:09.339973Z","shell.execute_reply.started":"2024-04-02T12:27:45.018400Z","shell.execute_reply":"2024-04-02T12:28:09.338753Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting intel-extension-for-pytorch\n  Downloading intel_extension_for_pytorch-2.2.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (7.0 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-pytorch) (5.9.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-pytorch) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-pytorch) (21.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->intel-extension-for-pytorch) (3.1.1)\nDownloading intel_extension_for_pytorch-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (52.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: intel-extension-for-pytorch\nSuccessfully installed intel-extension-for-pytorch-2.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom torchvision.utils import make_grid\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, jaccard_score\nimport requests\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive","metadata":{"id":"ppY0E2oBcXNu","outputId":"523f44ab-6260-44fd-8e22-1ec57ddd7605","execution":{"iopub.status.busy":"2024-03-31T12:29:19.187264Z","iopub.execute_input":"2024-03-31T12:29:19.187669Z","iopub.status.idle":"2024-03-31T12:29:19.19598Z","shell.execute_reply.started":"2024-03-31T12:29:19.187628Z","shell.execute_reply":"2024-03-31T12:29:19.195035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:29:19.198964Z","iopub.execute_input":"2024-03-31T12:29:19.199363Z","iopub.status.idle":"2024-03-31T12:29:42.490322Z","shell.execute_reply.started":"2024-03-31T12:29:19.199332Z","shell.execute_reply":"2024-03-31T12:29:42.488931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!gdown --id 13rRSkQMJVhotfO6wRlZGJqp9kNWFZjGX","metadata":{"execution":{"iopub.status.busy":"2024-03-31T12:29:42.491962Z","iopub.execute_input":"2024-03-31T12:29:42.492345Z","iopub.status.idle":"2024-03-31T12:29:59.830514Z","shell.execute_reply.started":"2024-03-31T12:29:42.49231Z","shell.execute_reply":"2024-03-31T12:29:59.829044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print Pytorch's version","metadata":{"id":"YyPnviwkoaRh"}},{"cell_type":"code","source":"torch.__version__","metadata":{"id":"uY8S0R76sj90","outputId":"012126c7-b199-473a-d7c3-88a22c6eeb3b","execution":{"iopub.status.busy":"2024-03-31T12:29:59.8332Z","iopub.execute_input":"2024-03-31T12:29:59.833573Z","iopub.status.idle":"2024-03-31T12:29:59.841295Z","shell.execute_reply.started":"2024-03-31T12:29:59.833538Z","shell.execute_reply":"2024-03-31T12:29:59.840282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check GPU","metadata":{"id":"8uWrMvwCbmsw"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"4NKtY3ESbmSl","outputId":"e54e9295-b586-4ee6-ff51-70e63e9dd854","execution":{"iopub.status.busy":"2024-03-31T12:29:59.842658Z","iopub.execute_input":"2024-03-31T12:29:59.842977Z","iopub.status.idle":"2024-03-31T12:30:02.720231Z","shell.execute_reply.started":"2024-03-31T12:29:59.842947Z","shell.execute_reply":"2024-03-31T12:30:02.718889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import Google Drive for persistent storage of our training data, neural network model weights and other required files","metadata":{"id":"mQ_bNRuloctt"}},{"cell_type":"markdown","source":"Empty GPU's memory/cache for training so we'd clear garbage values in it and more memory will be available","metadata":{"id":"go-hqw0wokrN"}},{"cell_type":"markdown","source":"## Custom Dataset Class\n\nCreate a custom dataset class that augments each image into 4 different angles: 0, 45, 90, 120, 180, 270, 300, 330 degrees. Fuse it with Pytorch's DataLoader class so data can be loaded, augmented and trained in realtime instead of caching all training samples in memory for augmenting.","metadata":{"id":"zjPKpYJTooMG"}},{"cell_type":"code","source":"class BrainTumorDataset(Dataset):\n  def __init__(self, images, labels):\n    # images\n    self.X = images\n    # labels\n    self.y = labels\n    \n    # Transformation for converting original image array to an image and then convert it to a tensor\n    self.transform = transforms.Compose([transforms.ToPILImage(),\n        transforms.ToTensor()\n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n    self.transform1 = transforms.Compose([\n        transforms.ToPILImage(),                                          \n        transforms.RandomRotation(45),\n        transforms.ToTensor()                                 \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n    self.transform2 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(90),\n        transforms.ToTensor()                                  \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n    self.transform3 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(120),\n        transforms.ToTensor()                                  \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n    self.transform4 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(180),\n        transforms.ToTensor()                                \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n    self.transform5 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(270),\n        transforms.ToTensor()                                \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n    self.transform6 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(300),\n        transforms.ToTensor()                               \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n    self.transform7 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(330),\n        transforms.ToTensor()                                 \n    ])\n\n  def __len__(self):\n    # return length of image samples\n    return len(self.X)\n\n  def __getitem__(self, idx):\n    # perform transformations on one instance of X\n    # Original image as a tensor\n    data = self.transform(self.X[idx])\n\n    # Augmented image at 45 degrees as a tensor\n    aug45 = self.transform1(self.X[idx])\n\n    # Augmented image at 90 degrees as a tensor\n    aug90 = self.transform2(self.X[idx])\n\n    # Augmented image at 120 degrees as a tensor\n    aug120 = self.transform3(self.X[idx])\n\n    # Augmented image at 180 degrees as a tensor\n    aug180 = self.transform4(self.X[idx])\n\n    # Augmented image at 270 degrees as a tensor\n    aug270 = self.transform5(self.X[idx])\n\n    # Augmented image at 300 degrees as a tensor\n    aug300 = self.transform6(self.X[idx])\n\n    # Augmented image at 330 degrees as a tensor\n    aug330 = self.transform7(self.X[idx])      \n    \n    # store the transformed images in a list\n    new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n\n    # one-hot encode the labels\n    labels = torch.zeros(4, dtype=torch.float32)\n    labels[int(self.y[idx])] = 1.0\n\n    new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n\n    # 8 augmented images and corresponding labels per sample will be returned\n    return (torch.stack(new_labels), torch.stack(new_batch))","metadata":{"id":"V4PuME0qmFvZ","execution":{"iopub.status.busy":"2024-03-31T12:30:02.722592Z","iopub.execute_input":"2024-03-31T12:30:02.723002Z","iopub.status.idle":"2024-03-31T12:30:03.77811Z","shell.execute_reply.started":"2024-03-31T12:30:02.722962Z","shell.execute_reply":"2024-03-31T12:30:03.776895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the Dataset\n\n* Load the **training_data.pickle** file. \n\n* Store the images and labels in separate lists called Xt & yt.","metadata":{"id":"zE6mTnC6pQRD"}},{"cell_type":"code","source":"training_data = pickle.load(open('/kaggle/working/training_data.pickle', 'rb'))","metadata":{"id":"trcS9hq8q7Dq","execution":{"iopub.status.busy":"2024-03-31T12:30:03.77959Z","iopub.execute_input":"2024-03-31T12:30:03.779965Z","iopub.status.idle":"2024-03-31T12:30:06.437927Z","shell.execute_reply.started":"2024-03-31T12:30:03.779932Z","shell.execute_reply":"2024-03-31T12:30:06.4369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create empty lists for storing our data","metadata":{"id":"-FUX5SScHhEg"}},{"cell_type":"code","source":"Xt = []\nyt = []\nfeatures = None\nlabels = None\nlabel = []","metadata":{"id":"hY6k--StlVAC","execution":{"iopub.status.busy":"2024-03-31T12:30:06.441281Z","iopub.execute_input":"2024-03-31T12:30:06.441581Z","iopub.status.idle":"2024-03-31T12:30:06.446286Z","shell.execute_reply.started":"2024-03-31T12:30:06.441557Z","shell.execute_reply":"2024-03-31T12:30:06.445291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Store images in Xt and labels in yt iteratively","metadata":{"id":"chU6n1FDHllX"}},{"cell_type":"code","source":"for features,labels in training_data:\n  Xt.append(features)\n  yt.append(labels)","metadata":{"id":"9gQx6_RtlwfE","execution":{"iopub.status.busy":"2024-03-31T12:30:06.447456Z","iopub.execute_input":"2024-03-31T12:30:06.447721Z","iopub.status.idle":"2024-03-31T12:30:06.459063Z","shell.execute_reply.started":"2024-03-31T12:30:06.447698Z","shell.execute_reply":"2024-03-31T12:30:06.458129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Validation Test split\n\nSplit the dataset for training using cross-validation method.\n\n* 70 % of images for training \n* 15% of images for validating\n* 15% of images for testing\n\nSet random seed and random_state to any arbitrary number, so the train_test_split happens the same way everytime the function is called.","metadata":{"id":"QOlU2ZoCpitc"}},{"cell_type":"code","source":"# 70 % training, 15% validating, 15% testing\nX_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, shuffle=True)  # 70% training, 30% testing\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)  # split testing set into 50% validation , 50% testing ","metadata":{"id":"wxT6Znuul5Kq","execution":{"iopub.status.busy":"2024-03-31T12:30:06.460348Z","iopub.execute_input":"2024-03-31T12:30:06.460729Z","iopub.status.idle":"2024-03-31T12:30:06.474785Z","shell.execute_reply.started":"2024-03-31T12:30:06.4607Z","shell.execute_reply":"2024-03-31T12:30:06.47386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Empty the previously used lists and arrays to free up RAM / Cache","metadata":{"id":"BWlXaeaVqINY"}},{"cell_type":"code","source":"Xt = None\nyt = None\nfeatures = None\nlabels = None\nlabel = None\ntraining_data = None ","metadata":{"id":"34qYiYRlJoXH","execution":{"iopub.status.busy":"2024-03-31T12:30:06.476137Z","iopub.execute_input":"2024-03-31T12:30:06.476466Z","iopub.status.idle":"2024-03-31T12:30:06.485866Z","shell.execute_reply.started":"2024-03-31T12:30:06.476437Z","shell.execute_reply":"2024-03-31T12:30:06.485026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create training set, validation set and test set using our custom dataset class","metadata":{"id":"oKlDZh7VqaJj"}},{"cell_type":"code","source":"train_set = BrainTumorDataset(X_train, y_train)\nvalid_set = BrainTumorDataset(X_valid, y_valid)\ntest_set = BrainTumorDataset(X_test, y_test)","metadata":{"id":"rnTKHLR5mCeI","execution":{"iopub.status.busy":"2024-03-31T12:30:06.487195Z","iopub.execute_input":"2024-03-31T12:30:06.487518Z","iopub.status.idle":"2024-03-31T12:30:06.498846Z","shell.execute_reply.started":"2024-03-31T12:30:06.487489Z","shell.execute_reply":"2024-03-31T12:30:06.497954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print original number of samples in each set","metadata":{"id":"tfWO3u4YqiUP"}},{"cell_type":"code","source":"print(f\"Number of training samples: {len(X_train)}\")\nprint(f\"Number of validation samples: {len(X_valid)}\")\nprint(f\"Number of testing samples: {len(X_test)}\")","metadata":{"id":"MEL7oQ4Y8NIe","outputId":"b4d33819-b7f1-4b5a-ce44-d7aa9c9d9b0c","execution":{"iopub.status.busy":"2024-03-31T12:30:06.500738Z","iopub.execute_input":"2024-03-31T12:30:06.501579Z","iopub.status.idle":"2024-03-31T12:30:06.51035Z","shell.execute_reply.started":"2024-03-31T12:30:06.50154Z","shell.execute_reply":"2024-03-31T12:30:06.509286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print augmented number of samples in each set","metadata":{"id":"0udsS0Qqql3g"}},{"cell_type":"code","source":"print(f\"Number of augmented training samples: {len(X_train) * 8}\")\nprint(f\"Number of augmented validation samples: {len(X_valid)* 8}\")\nprint(f\"Number of augmented testing samples: {len(X_test)* 8}\")","metadata":{"id":"8PJu7hjEi0Ij","outputId":"b9cb23ac-8182-4b4b-cd7f-d7b93670b615","execution":{"iopub.status.busy":"2024-03-31T12:30:06.511562Z","iopub.execute_input":"2024-03-31T12:30:06.512194Z","iopub.status.idle":"2024-03-31T12:30:06.521355Z","shell.execute_reply.started":"2024-03-31T12:30:06.512159Z","shell.execute_reply":"2024-03-31T12:30:06.520277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a DataLoader for each set with batch size of 4 and shuffling enabled","metadata":{"id":"S9XaKzTZqpW0"}},{"cell_type":"code","source":"train_gen = DataLoader(train_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\nvalid_gen = DataLoader(valid_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\ntest_gen = DataLoader(test_set, batch_size=10, shuffle=True, pin_memory=True, num_workers=8)","metadata":{"id":"-5Eil06jrRUT","execution":{"iopub.status.busy":"2024-03-31T12:30:06.522768Z","iopub.execute_input":"2024-03-31T12:30:06.523159Z","iopub.status.idle":"2024-03-31T12:30:06.546295Z","shell.execute_reply.started":"2024-03-31T12:30:06.523127Z","shell.execute_reply":"2024-03-31T12:30:06.545409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get device to set the training to run on GPU or CPU later based on its availibility","metadata":{"id":"VE1aH9bJq1HD"}},{"cell_type":"code","source":"device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice = torch.device(device_name)\ndevice","metadata":{"id":"ka_a8OAPtNHY","execution":{"iopub.status.busy":"2024-03-31T12:30:06.54967Z","iopub.execute_input":"2024-03-31T12:30:06.54998Z","iopub.status.idle":"2024-03-31T12:30:06.558993Z","shell.execute_reply.started":"2024-03-31T12:30:06.549954Z","shell.execute_reply":"2024-03-31T12:30:06.558163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the Model\n\n* Instantiate the transfer learning model using torchvision's models class.\n\n* RESNET50 is the CNN model that we're going to use by transfer learning.\n\n* Set all the pretrained weights to trainable by enabling every layer's parameters as true\n\n* Build the top layer by creating a custom output sequential layer and assign it to model's fc.","metadata":{"id":"eHncA4uwrAnB"}},{"cell_type":"code","source":"# instantiate transfer learning model\nresnet_model = models.resnet50(pretrained=True)\n\n# set all paramters as trainable\nfor param in resnet_model.parameters():\n    param.requires_grad = True\n\n# get input of fc layer\nn_inputs = resnet_model.fc.in_features\n\n# redefine fc layer / top layer/ head for our classification problem\nresnet_model.fc = nn.Sequential(nn.Linear(n_inputs, 2048),\n                                nn.SELU(),\n                                nn.Dropout(p=0.4),\n                                nn.Linear(2048, 2048),\n                                nn.SELU(),\n                                nn.Dropout(p=0.4),\n                                nn.Linear(2048, 4),\n                                nn.LogSigmoid())\n\n# set all paramters of the model as trainable\nfor name, child in resnet_model.named_children():\n  for name2, params in child.named_parameters():\n    params.requires_grad = True\n\n# set model to run on GPU or CPU absed on availibility\nresnet_model.to(device)\n\n# print the trasnfer learning NN model's architecture\nresnet_model","metadata":{"id":"Lq3_lCEttAJk","outputId":"feb12130-9d1d-4c44-d546-6327f266745a","execution":{"iopub.status.busy":"2024-03-31T12:30:06.560095Z","iopub.execute_input":"2024-03-31T12:30:06.560419Z","iopub.status.idle":"2024-03-31T12:30:07.230886Z","shell.execute_reply.started":"2024-03-31T12:30:06.560384Z","shell.execute_reply":"2024-03-31T12:30:07.229856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Training Configuration\n\n* Set model's loss function as CrossEntropyLoss\n\n* Set SGD optimizer with 0.9 momentum and learning rate 3e-4 as the model's optimizer. According to many Deep learning experts and researchers such as [Andrej karpathy](https://github.com/karpathy) 3e-4 is a good learning rate choice.\n\n* Run the model for 10 total iterations\n\n* Create empty lists to store training losses, validation losses, training accuracies, and validation accuracies.","metadata":{"id":"_QdrEPESsKQi"}},{"cell_type":"code","source":"# loss function\n# if GPU is available set loss function to use GPU\ncriterion = nn.CrossEntropyLoss().to(device)\n\n# optimizer\noptimizer = torch.optim.SGD(resnet_model.parameters(), momentum=0.9, lr=3e-4)\n\n# number of training iterations\nepochs = 30\n\n# empty lists to store losses and accuracies\ntrain_losses = []\ntest_losses = []\ntrain_correct = []\ntest_correct = []","metadata":{"id":"cokrpXp3ud8_","execution":{"iopub.status.busy":"2024-03-31T12:30:07.232467Z","iopub.execute_input":"2024-03-31T12:30:07.232834Z","iopub.status.idle":"2024-03-31T12:30:07.247728Z","shell.execute_reply.started":"2024-03-31T12:30:07.2328Z","shell.execute_reply":"2024-03-31T12:30:07.24677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Util function\n\n### Checkpoint Saver\nA function to save the model using checkpoints based on best loss achieved during every iteration compared with previous iteration's loss. We'll load the checkpoint and resume training in case Colab's runtime get's disconnected due to inactivity or any other issues.","metadata":{"id":"7E_rg4eJs7Xq"}},{"cell_type":"code","source":"def save_checkpoint(state, is_best, filename='bt_resnet50_ckpt_v2.pth.tar'):\n    torch.save(state, filename)","metadata":{"id":"MnUksQpFNxNK","execution":{"iopub.status.busy":"2024-03-31T12:30:07.249036Z","iopub.execute_input":"2024-03-31T12:30:07.249459Z","iopub.status.idle":"2024-03-31T12:30:07.263309Z","shell.execute_reply.started":"2024-03-31T12:30:07.249428Z","shell.execute_reply":"2024-03-31T12:30:07.262382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{"id":"Ci1Lw3UgtU13"}},{"cell_type":"code","source":"# set training start time\nstart_time = time.time()\n\n# set best_prec loss value as 2 for checkpoint threshold\nbest_prec1 = 2\n\n# empty batch variables\nb = None\ntrain_b = None\ntest_b = None\n\n# start training\nfor i in range(epochs):\n    print(i)\n    # empty training correct and test correct counter as 0 during every iteration\n    trn_corr = 0\n    tst_corr = 0\n    \n    # set epoch's starting time\n    e_start = time.time()\n    \n    # train in batches\n    for b, (y, X) in enumerate(train_gen):\n        # set label as cuda if device is cuda\n        X, y = X.to(device), y.to(device)\n\n        # forward pass image sample\n        y_pred = resnet_model(X.view(-1, 3, 512, 512))\n        # calculate loss\n        loss = criterion(y_pred.float(), torch.argmax(y.view(32, 4), dim=1).long())\n\n        # get argmax of predicted tensor, which is our label\n        predicted = torch.argmax(y_pred, dim=1).data\n        # if predicted label is correct as true label, calculate the sum for samples\n        batch_corr = (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n        # increment train correct with correcly predicted labels per batch\n        trn_corr += batch_corr\n        \n        # set optimizer gradients to zero\n        optimizer.zero_grad()\n        # back propagate with loss\n        loss.backward()\n        # perform optimizer step\n        optimizer.step()\n\n    # set epoch's end time\n    e_end = time.time()\n    # print training metrics\n    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n\n    # some metrics storage for visualization\n    train_b = b\n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n\n    X, y = None, None\n\n    # validate using validation generator\n    # do not perform any gradient updates while validation\n    with torch.no_grad():\n        for b, (y, X) in enumerate(valid_gen):\n            # set label as cuda if device is cuda\n            X, y = X.to(device), y.to(device)\n\n            # forward pass image\n            y_val = resnet_model(X.view(-1, 3, 512, 512))\n\n            # get argmax of predicted tensor, which is our label\n            predicted = torch.argmax(y_val, dim=1).data\n\n            # increment test correct with correcly predicted labels per batch\n            tst_corr += (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n\n    # get loss of validation set\n    loss = criterion(y_val.float(), torch.argmax(y.view(32, 4), dim=1).long())\n    # print validation metrics\n    print(f'Validation Accuracy {tst_corr.item()*100/(4*8*b):2.2f} Validation Loss: {loss.item():2.4f}\\n')\n\n    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n    is_best = loss < best_prec1\n    best_prec1 = min(loss, best_prec1)\n    save_checkpoint({\n            'epoch': i + 1,\n            'state_dict': resnet_model.state_dict(),\n            'best_prec1': best_prec1,\n        }, is_best)\n\n    # some metrics storage for visualization\n    test_b  = b\n    test_losses.append(loss)\n    test_correct.append(tst_corr)\n\n# set total training's end time\nend_time = time.time() - start_time    \n\n# print training summary\nprint(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\nprint(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\nprint(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))","metadata":{"id":"0TWAlOEau6k7","outputId":"d1c0a256-466f-4420-c9ad-a1bf15630b97","execution":{"iopub.status.busy":"2024-03-31T12:30:07.264756Z","iopub.execute_input":"2024-03-31T12:30:07.265119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"U5hiXkZkwW-W","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the model\n\nSave the model after the training is completed","metadata":{"id":"9Rzl2f2kteb8"}},{"cell_type":"code","source":"torch.save(resnet_model.state_dict(), '/content/drive/My Drive/bt_resnet50_model.pt')","metadata":{"id":"K4yzcJMmwPnY","execution":{"iopub.status.busy":"2024-03-31T12:28:46.213783Z","iopub.status.idle":"2024-03-31T12:28:46.214246Z","shell.execute_reply.started":"2024-03-31T12:28:46.213998Z","shell.execute_reply":"2024-03-31T12:28:46.214016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{"id":"Q-2R8Yputlvh"}},{"cell_type":"markdown","source":"Print the validation accuracy of the model calculated using validation set during training ","metadata":{"id":"hPEBr7E1tobU"}},{"cell_type":"code","source":"print(f'Validation accuracy: {test_correct[-1].item()*100/(test_b*8*4):.2f}%')","metadata":{"id":"4w0EuNLQvmNV","outputId":"685ce068-21f1-4419-c278-555cde282b40","execution":{"iopub.status.busy":"2024-03-31T12:28:46.215834Z","iopub.status.idle":"2024-03-31T12:28:46.216591Z","shell.execute_reply.started":"2024-03-31T12:28:46.216355Z","shell.execute_reply":"2024-03-31T12:28:46.216375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the loss graph","metadata":{"id":"EnauSi8Dt04I"}},{"cell_type":"code","source":"plt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.title('Loss Metrics')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","metadata":{"id":"TttSopdFvtr0","outputId":"6bc80323-bb7c-4a70-eae5-544ed8c363fb","execution":{"iopub.status.busy":"2024-03-31T12:28:46.217844Z","iopub.status.idle":"2024-03-31T12:28:46.218315Z","shell.execute_reply.started":"2024-03-31T12:28:46.218069Z","shell.execute_reply":"2024-03-31T12:28:46.218104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the accuracy graph\n\n* Training set - Total length of training samples divided by 100 for every trained sample\n\n  * `int((2144 * 8)/100) = int(171.52) = 171`\n\n* Testing set - Total length of testing samples divided by 100 for every testing sample\n\n  * `int((460 * 8)/100) = int(36.8) = 36`\n\n\n","metadata":{"id":"8L-_dup0uCl5"}},{"cell_type":"code","source":"plt.plot([t/171 for t in train_correct], label='Training accuracy')\nplt.plot([t/36 for t in test_correct], label='Validation accuracy')\nplt.title('Accuracy Metrics')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","metadata":{"id":"YKzECNFZvx9u","outputId":"7a995797-5511-4b7d-8227-ea9af093cc18","execution":{"iopub.status.busy":"2024-03-31T12:28:46.219396Z","iopub.status.idle":"2024-03-31T12:28:46.219858Z","shell.execute_reply.started":"2024-03-31T12:28:46.219617Z","shell.execute_reply":"2024-03-31T12:28:46.219636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Empty out training set and validation set to free up RAM / Cache","metadata":{"id":"nEKbGLWsIt6P"}},{"cell_type":"code","source":"# resnet_model.load_state_dict(torch.load('/content/drive/My Drive/bt_resnet_torch.pt'))\ntrain_gen = None\nvalid_gen = None\ntrain_set = None\nvalid_set = None","metadata":{"id":"SsVJuIwych21","execution":{"iopub.status.busy":"2024-03-31T12:28:46.221402Z","iopub.status.idle":"2024-03-31T12:28:46.221825Z","shell.execute_reply.started":"2024-03-31T12:28:46.22161Z","shell.execute_reply":"2024-03-31T12:28:46.221629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set model to evaluation mode\n\nCalculate loss, correctly classified samples, predicted values, labels and store them in a list using test dataloader","metadata":{"id":"LfVhP2dmvdoi"}},{"cell_type":"code","source":"# set model to evaluation mode\nresnet_model.eval()\n\n# perform no gradient updates\nwith torch.no_grad():\n    # soem metrics storage for visualization and analysis\n    correct = 0\n    test_loss = []\n    test_corr = []\n    labels = []\n    pred = []\n    # perform test set evaluation batch wise\n    for (y, X) in test_gen:\n        # set label to use CUDA if available\n        X, y = X.to(device), y.to(device)\n\n        # append original labels\n        labels.append(torch.argmax(y.view(10 * 8, 4), dim=1).data)\n\n        # perform forward pass\n        y_val = resnet_model(X.view(-1, 3, 512, 512))\n\n        # get argmax of predicted values, which is our label\n        predicted = torch.argmax(y_val, dim=1).data\n        # append predicted label\n        pred.append(predicted)\n\n        # calculate loss\n        loss = criterion(y_val.float(), torch.argmax(y.view(10 * 8, 4), dim=1).long())\n\n        # increment correct with correcly predicted labels per batch\n        correct += (predicted == torch.argmax(y.view(10 * 8, 4), dim=1)).sum()\n\n        # append correct samples labels and losses\n        test_corr.append(correct)\n        test_loss.append(loss)\n        \nprint(f\"Test Loss: {test_loss[-1].item():.4f}\")","metadata":{"id":"WZJ7w9ztv1pb","outputId":"e59c6347-59f8-42e8-aff4-c95e2567f495","execution":{"iopub.status.busy":"2024-03-31T12:28:46.222922Z","iopub.status.idle":"2024-03-31T12:28:46.223369Z","shell.execute_reply.started":"2024-03-31T12:28:46.223147Z","shell.execute_reply":"2024-03-31T12:28:46.223165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the test accuracy\n","metadata":{"id":"AqDm19ZSvyY2"}},{"cell_type":"code","source":"print(f'Test accuracy: {test_corr[-1].item()*100/(460*8):.2f}%')","metadata":{"id":"HJm2yjzHbLlP","outputId":"7b227ca6-3d4d-44cd-a030-a0e0cc8d744e","execution":{"iopub.status.busy":"2024-03-31T12:28:46.224566Z","iopub.status.idle":"2024-03-31T12:28:46.224997Z","shell.execute_reply.started":"2024-03-31T12:28:46.224768Z","shell.execute_reply":"2024-03-31T12:28:46.224787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert list of tensors to tensors","metadata":{"id":"T6fxSb68v0uf"}},{"cell_type":"code","source":"labels = torch.stack(labels)\npred = torch.stack(pred)","metadata":{"id":"jDRv0IhThKhP","execution":{"iopub.status.busy":"2024-03-31T12:28:46.22602Z","iopub.status.idle":"2024-03-31T12:28:46.22646Z","shell.execute_reply.started":"2024-03-31T12:28:46.226238Z","shell.execute_reply":"2024-03-31T12:28:46.226257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define ground-truth labels as a list","metadata":{"id":"Ps2QnU4ov4Sr"}},{"cell_type":"code","source":"LABELS = ['Meningioma', 'Glioma', 'Pitutary']","metadata":{"id":"7BsASCMlL2_z","execution":{"iopub.status.busy":"2024-03-31T12:28:46.229719Z","iopub.status.idle":"2024-03-31T12:28:46.230174Z","shell.execute_reply.started":"2024-03-31T12:28:46.229941Z","shell.execute_reply":"2024-03-31T12:28:46.229958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the confusion matrix","metadata":{"id":"wubHPKqov61w"}},{"cell_type":"code","source":"arr = confusion_matrix(pred.view(-1).cpu(), labels.view(-1).cpu())\ndf_cm = pd.DataFrame(arr, LABELS, LABELS)\nplt.figure(figsize = (9,6))\nsns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Target\")\nplt.show()","metadata":{"id":"3cfoG8Q0gMKZ","outputId":"95a96f4c-bf40-4efd-a0f2-31d5606c657a","execution":{"iopub.status.busy":"2024-03-31T12:28:46.231376Z","iopub.status.idle":"2024-03-31T12:28:46.231808Z","shell.execute_reply.started":"2024-03-31T12:28:46.23159Z","shell.execute_reply":"2024-03-31T12:28:46.231608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the classification report","metadata":{"id":"kHhrPo6Tv9Xc"}},{"cell_type":"code","source":"print(f\"Clasification Report\\n\\n{classification_report(pred.view(-1).cpu(), labels.view(-1).cpu())}\")","metadata":{"id":"MNWrpWVXL_pQ","outputId":"4dd25c3d-45e9-4c8c-cf56-11c58a41cecd","execution":{"iopub.status.busy":"2024-03-31T12:28:46.232982Z","iopub.status.idle":"2024-03-31T12:28:46.233425Z","shell.execute_reply.started":"2024-03-31T12:28:46.233206Z","shell.execute_reply":"2024-03-31T12:28:46.233224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the Jaccard Similarity score / Index (Accuracy)","metadata":{"id":"N5xUvujSwBQc"}},{"cell_type":"code","source":"print(f\"Jaccard Index\\n\\n{round(jaccard_similarity_score(pred.view(-1).cpu(), labels.view(-1).cpu()), 2)}\")","metadata":{"id":"WXiYK3JxMC3F","outputId":"f4288b40-ded1-491d-b242-6c052b3dcbc6","execution":{"iopub.status.busy":"2024-03-31T12:28:46.23487Z","iopub.status.idle":"2024-03-31T12:28:46.235324Z","shell.execute_reply.started":"2024-03-31T12:28:46.2351Z","shell.execute_reply":"2024-03-31T12:28:46.235118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've got around 99% test accuracy which is really good. ","metadata":{"id":"Qw0YkS8kbs8q"}},{"cell_type":"markdown","source":"## Future Scopes\n\n* The model will be deployed using python flask server as a website, so anyone could an upload MRI image of brain and find out what kinda tumor is present (if any).\n\n* Tumor detection will be added in future to locate where the tumor is present in the given MRI image of the brain.\n\n* Will add more sophisticated regularization techniques to prevent slight overfitting and increase accuracy upto 100 %.","metadata":{"id":"HOzZqnNq2EyF"}}]}